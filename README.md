# inv_kinematics



This repository explains and shows the development of the thrid Lab, which main objective is to learn about inverse kinematics and trajectories.

Firstly, it is needed to remember the phantom X model, in which the inverse kinematics are developed.

The set of tools used in this aplication are the following libraries, specially spatialmath.base and RTB are the main tools to develop the Phantom model, the inverse kinematics, aditionally, position and rotation descriptions.
## Procedure

```python
from ctypes import sizeof
from json import tool
from unicodedata import name
import roboticstoolbox as rtb
from spatialmath import SE3
import numpy as np
from spatialmath.base import *
```
The model generated by RTB is shown below, this model  is constructed based on DHstd parameters gotten on the previous Lab (https://github.com/Wassau/Control-Px_robot.git). In this case it is important to set a tool, in order to check the orientation of the places that are chosen to track.
```python

Pincher = rtb.DHRobot(
    [
        rtb.RevoluteDH(alpha= np.pi/2, d= 14.45),
        rtb.RevoluteDH(a=10.49,offset=np.pi/2),
        rtb.RevoluteDH(a=10.7),
        rtb.RevoluteDH(alpha=np.pi/2)

    ], name="Pincher",
        # tool =SE3(transl(0 , 0 , 8))
)
```
After measuring the position of the targets, the inverse kinematics are calculated due to this poses, those are developed with the SE3 objects in the form of position * orientation. Afterwards, rtb.jtraj is used to make the joint trajectory; this method receives 3 parameters: initial joint configuration, final joint configuration and the number of steps between those configurations. By this way, the intermediate steps are calculated, in order to improve the movement between poses.

This process is iterative, this base code is implemented in the other positions to pick and place the objects type 1 and type 2. 

The ikine_LM is a numeric method in order to find out the inverse kinematics from a initial configuration condition, in this case, there is not a initial condition, but in the further codes that replies this one, the parameter is an input of q0=. This method uses a Levenberg-Marquadt optimization.
```python
T0 = SE3( 4, -4, 11 ) * SE3.OA([0, 1, 0], [0, 0, -1]) 
sol0 = Pincher.ikine_LM(T0)  
print('Pose1')
print(np.rad2deg(sol0.q))
qf = Pincher.fkine(np.round(sol0.q))
qt = rtb.jtraj([0, -np.pi/3, -np.pi/3, 0], sol0.q, 10)
qtdeg = np.rad2deg(np.round(qt.q))
print(qtdeg[1])
input()
for i in range(len(qt)):
    # q = Pincher.ikine_LM(qt[i],q0= config )
    # config = np.rad2deg(np.round(q.q))
    t2=qt.q[i]
    print(np.rad2deg(np.round(qt.q[i])))
    Pincher.plot(qt.q[i])
```
In this way the trajectories and positions have been plotted and obtained, so, the next step is just going into the drivers, in this step the code is recycled from px_robot repository using the roslauncher of px_controllers, also the Jointcommand methods are useful.

The next method transforms the joint configurations gotten previously  into driver's commands from 0 to 1023 bits of position; additionaly, it is important to taking into account the boundaries of the motors. The code below shows how the joint configurations are read by the drivers.
```python
def drive(array):
    jointCommand('',3,'Goal_Position', round(-array[2]/300 * 1023 + 512),0.2)
    print(round(array[2]/300 * 1023 + 512))
    print(type(round(array[2]/300 * 1023 + 512)))
    time.sleep(0.5)
    jointCommand('',4,'Goal_Position', round(-array[3]/1023 * 300 + 512),0.2)
    print(round(array[3]/300 * 1023  + 512))
    time.sleep(0.5)
    jointCommand('',2,'Goal_Position', round(array[1]/1023 * 300 + 512),0.2)
    print(round(array[1]/300 * 1023  + 512))
    time.sleep(0.5)
    jointCommand('',1,'Goal_Position', round(array[0]/300 * 1023  + 512),0.2)
```s

https://youtu.be/l49hyLJMKvs
## Acknowledgments:
Co-authored-by: Alejandro Triana <alejotriana1@users.noreply.github.com> 